\documentclass[12pt,twoside]{article}
\linespread{1.5} 
\usepackage[T1]{fontenc}
\usepackage{textalpha}

\usepackage{textgreek}
\usepackage[english, greek]{babel}
\usepackage[numbers]{natbib}
\usepackage{url}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath, amssymb, amsfonts}
\usepackage{graphicx}
\graphicspath{{images/}}
\usepackage{rotating}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{comment} 
\usepackage{lettrine}
\usepackage{type1cm}
\usepackage{vmargin}
\setmarginsrb{3cm}{1.5cm}{3cm}{2.5cm}{1cm}{1.5cm}{1cm}{1.5cm}
\usepackage{bm}
\usepackage{csquotes}
\renewcommand*\descriptionlabel[1]{\hspace\leftmargin$#1$}
\usepackage{enumitem} 
\usepackage{commath}
\usepackage{listings}
\usepackage{breakcites}
\usepackage[hidelinks]{hyperref}
\usepackage{footnote}
\usepackage[nottoc]{tocbibind}
\usepackage[caption=false, font=footnotesize]{subfig}
\usepackage[export]{adjustbox}
\usepackage{titlesec}

\usepackage{algorithm}
\usepackage{algorithmic}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}

\renewcommand{\algorithmicensure}{\textbf{Output:}}
\setcitestyle{square}

\newcommand{\en}{\selectlanguage{english}}
\newcommand{\gr}{\selectlanguage{greek}}
\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup


}

\titleclass{\subsubsubsection}{straight}[\subsubsection]
\newcounter{subsubsubsection}[subsubsection]

\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\titleformat{\subsubsubsection}[runin]
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1em}

\gr
\title{\gr Ανάπτυξη συστήματος αναγνώρισης μεροληψίας σε μεθόδους μηχανικής μάθησης}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE,RO]{\itshape\nouppercase{\rightmark}}
\cfoot{\thepage}

\begin{document}
\raggedbottom

\begin{titlepage}
\en
    \centering
    \includegraphics[scale = 0.75]{logo.png}\\[0.0 cm]  % University Logo
    \textsc{\gr \Huge Πολυτεχνική Σχολή \\ Τμημα μηχανικων η/υ και πληροφορικης}\\[0.5 cm]  % University Name
    \rule{\linewidth}{0.2 mm} \\[0.4 cm]
    { \Large \bfseries \gr Ανάπτυξη συστήματος αναγνώρισης μεροληψίας σε μεθόδους μηχανικής μάθησης}\\
    \rule{\linewidth}{0.2 mm} \\[0.4 cm]
    \gr \textbf{\Large{ΔΙΠΛΩΜΑΤΙΚΗ ΕΡΓΑΣΙΑ}\\}
    \large {του Ορέστη Ι. Τσαγκέτα }\\[1.0cm]
    \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \normalsize
            \textbf{\emph{\gr Επιβλέπων:}\\}
            \gr Χρήστος Μακρής\\
            \gr Αναπληρωτής Καθηγητής\\
            \gr Τμήμα Μηχανικών Η/Υ και Πληροφορικής\\
            \gr Πανεπιστήμιο Πατρών\\
        \end{flushleft}
    \end{minipage}~
    \begin{minipage}{0.4\textwidth}
        \begin{flushright} \normalsize
            \textbf{\emph{\gr Συνεπιβλέπον:} \\}
            \gr Ιωάννης Κανελλόπουλος\\
	 \vspace{4\baselineskip} % Adjust the space here to match the other minipage
        \end{flushright}
    \end{minipage}\\[0.5 cm]
    \gr \small {\textbf{Πάτρα, Σεπτέμβριος 2024 }}
\end{titlepage}


\pagenumbering{arabic}
\newpage
\vspace*{\fill}
\hspace{-7.5mm}
\textbf{\en Copyright © \gr Ορέστης Ι. Τσαγκέτας, 2024\\
Με επιφύλαξη παντός δικαιώματος. \en All rights reserved.\gr\\}
\hspace{-7.5mm}\\
\textbf{Απαγορεύεται}  η  αντιγραφή, η αποθήκευση  και η διανομή  της  παρούσας  εργασίας,  εξ’ ολοκλήρου ή τμήματος αυτής, για εμπορικό σκοπό.
Επιτρέπεται η ανατύπωση, η αποθήκευση και η διανομή  για  σκοπό  μη-κερδοσκοπικό,  εκπαίδευσης  ή  ερευνητικής  φύσης,  υπό  την 
προϋπόθεση  να  αναφέρεται  η  πηγή  προέλευσης  και  να διατηρείται το  παρόν  μήνυμα. 
Ερωτήματα  που  αφορούν  τη  χρήση  της  εργασίας  για  κερδοσκοπικό  σκοπό  πρέπει  να 
απευθύνονται προς τον συγγραφέα.\\
\hspace{-7.5mm}\\
Οι  απόψεις  και  τα  συμπεράσματα  που  περιέχονται  σε  αυτό  το  έγγραφο  εκφράζουν  τον 
συγγραφέα  και  δεν  πρέπει  να  ερμηνευθεί  ότι  αντιπροσωπεύουν  τις  επίσημες  θέσεις  του 
Πανεπιστημίου Πατρών.

\thispagestyle{empty}
\newpage

%ΠΕΡΙΛΗΨΗ
\thispagestyle{plain}
\paragraph{\Large{\gr Περίληψη}}
\
\\
\vspace{-0.7cm}
\gr
\lettrine[loversize=0.03]{\en H} \gr παρούσα διπλωματική εργασία ασχολείται με τη σχεδίαση και ανάπτυξη ενός εργαλείου που στοχεύει στον εντοπισμό και τη μείωση της μεροληψίας σε μεθόδους μηχανικής μάθησης. Το εργαλείο, το οποίο είναι μια διαδικτυακή εφαρμογή, αναπτύχθηκε σε \en Python \gr χρησιμοποιώντας το \en Flask Framework \gr και την εργαλειοθήκη \en Aif360 \gr της \en IBM \gr. Οι χρήστες της εφαρμογής καλούνται να ανεβάσουν ένα \en dataset \gr με το οποίο εκπαιδεύουν ένα από τα διαθέσιμα μοντέλα μηχανικής μάθησης. Ο έλεγχος της μεροληψίας πραγματοποιείται βάσει του χαρακτηριστικού που επιλέγει ο χρήστης να ελεγχθεί, και αν επιβεβαιωθούν οι υποψίες του, να μειωθεί. Αυτή η διαδικασία διενεργείται μέσω της εφαρμογής, χρησιμοποιώντας διάφορες μετρικές μεροληψίας. Η μείωση της μεροληψίας επιτυγχάνεται με τη χρήση συγκεκριμένων αλγορίθμων, τους οποίους ο χρήστης μπορεί να επιλέξει ανάλογα με τις ανάγκες του. Για τη σωστή επιλογή των μετρικών και των αλγορίθμων, η εφαρμογή παρέχει καθοδήγηση στον χρήστη, λαμβάνοντας υπόψη τους περιορισμούς που προκύπτουν από τα χαρακτηριστικά των δεδομένων. Ο βασικός στόχος αυτής της διπλωματικής εργασίας είναι η εκπαίδευση και εξοικείωση των χρηστών που δεν διαθέτουν προγραμματιστικές γνώσεις ή βαθιά κατανόηση της μηχανικής μάθησης με την έννοια της δικαιοσύνης στους αλγορίθμους μηχανικής μάθησης. Επιπλέον, η εφαρμογή θα ελεγχθεί ώστε τα αποτελέσματά της να συμμορφώνονται με τον νόμο \en Local Law 144 of 2021 \gr, που επιβάλλεται από το \en NYC Department of Consumer and Worker Protection (DCWP) \gr. Ο νόμος αυτός απαιτεί διαφάνεια και δίκαιες πρακτικές στις αποφάσεις που λαμβάνονται μέσω αυτοματοποιημένων συστημάτων λήψης αποφάσεων, διασφαλίζοντας ότι δεν υπάρχει μεροληψία κατά συγκεκριμένων ομάδων πληθυσμού.

\paragraph{\large{\gr Λέξεις Κλειδιά: Αλγοριθμική Δικαιοσύνη, Μετρικές Δικαιοσύνης, Αλγόριθμοι Μείωσης Μεροληψίας, Μηχανική Μάθηση , \en Python\gr, \en Aif360\gr, \en Flask\gr, \en Local Law 144 of 2021\gr}}
%ABSTRACT
\newpage
\thispagestyle{plain}
\paragraph{\Large{\en Abstract}}
\
\\
\vspace{-0.7cm}
\en
\lettrine [loversize = 0.03] {\en T} {\ he} current Diploma Thesis focuses on the design and development of a tool aimed at detecting and reducing bias in machine learning methods. The tool, which is a web application, was developed in Python using the Flask Framework and the Aif360 toolkit from IBM. Users of the application are required to upload a dataset with which they train one of the available machine learning models. Bias detection is conducted based on the characteristic selected by the user to be checked, and if their suspicions are confirmed, to be reduced. This process is carried out through the application using various bias metrics. Bias reduction is achieved using specific algorithms that the user can choose based on their needs. For the correct selection of metrics and algorithms, the application provides guidance to the user, taking into account the constraints arising from the characteristics of the data. The primary goal of this thesis is to educate and familiarize users who do not have programming knowledge or a deep understanding of machine learning with the concept of fairness in machine learning algorithms. Additionally, the application will be tested to ensure its results comply with Local Law 144 of 2021, enforced by the NYC Department of Consumer and Worker Protection (DCWP). This law requires transparency and fair practices in decisions made through automated decision systems, ensuring that there is no bias against specific population groups.

\paragraph{\large{\en Keywords: Algorithmic Justice, Justice Metrics, Bias Reduction Algorithms, Machine Learning, Python, Aif360, Flask, Local Law 144 of 2021}}

\newpage\null
\thispagestyle{plain}
\vspace*{\fill}
\begin{center}
\begin{minipage}{.6\textwidth}
\centering \textbf{\en\textit{ “Being good is easy, what is difficult is being just.”}
\rightline{{\rm ---  Victor Hugo}}}%\gr Σκοπίμως κενή σελίδα}
\end{minipage}
\end{center}
\vfill

%ΕΥΧΑΡΙΣΤΙΕΣ
\newpage
\thispagestyle{plain}
\paragraph{\Large{\gr Ευχαριστίες}}
\paragraph{}
\gr Θα ήθελα να ευχαριστήσω κ. Γ. Κανελλόπουλο και τον καθηγητή  κ. Χρήστο Μακρή  και  για την επίβλεψη  αλλά και για τη συμβολή τους στην εκπόνηση αυτής της διπλωματικής εργασίας.
\paragraph{}
Τέλος θα ήθελα να ευχαριστήσω τους γονείς μου για τη υποστήριξη και την ηθική συμπαράσταση που μου προσέφεραν όλα αυτά τα χρόνια.

\hspace{8cm} \textbf{\textit{Πάτρα, 1 Σεπτεμβρίου 2024}}

\newpage
\thispagestyle{empty}
\null

\gr
\newpage
\thispagestyle{plain}
\tableofcontents

\gr
\newpage
\thispagestyle{plain}
\listoffigures

\newpage
\thispagestyle{plain}
\listoftables

\newpage\null
\thispagestyle{empty}

\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%ΕΙΣΑΓΩΓΗ
\newpage
\thispagestyle{plain}
\null
\vspace{2cm}
\hspace{-6.5mm}{\textbf{\Huge
 \gr Κεφάλαιο 1: Εισαγωγή}}
\vspace{-4mm}
\section{\gr Εισαγωγή}
\gr

\paragraph{}\gr
Η ευρεία υιοθέτηση της μηχανικής μάθησης (ML) σε διάφορους τομείς, από εγκρίσεις δανείων και συστήματα αναγνώρισης προσώπου μέχρι προβλέψεις στην ποινική δικαιοσύνη, έχει φέρει σημαντικά οφέλη στην κοινωνία. Ωστόσο, υπάρχει μια αυξανόμενη ανησυχία σχετικά με τη δυνατότητα εμφάνισης προκαταλήψεων σε αυτούς τους ισχυρούς αλγόριθμους. Οι προκαταλήψεις στα μοντέλα ML μπορούν να οδηγήσουν σε άδικα και διακριτικά αποτελέσματα, ιδιαίτερα όταν εμπλέκονται ευαίσθητα δεδομένα, πιθανώς διαιωνίζοντας τις υπάρχουσες κοινωνικές ανισότητες.

Αυτή η διπλωματική εργασία ασχολείται με το κρίσιμο ζήτημα της ανίχνευσης και μείωσης των προκαταλήψεων στις μεθόδους ML. Παρουσιάζουμε το σχεδιασμό και την ανάπτυξη μιας φιλικής προς τον χρήστη διαδικτυακής εφαρμογής που δίνει τη δυνατότητα σε άτομα, ακόμη και χωρίς εκτεταμένη γνώση προγραμματισμού, να εντοπίζουν και να μειώνουν τις πιθανές προκαταλήψεις στα μοντέλα μηχανικής μάθησης τους.

Αυτή η εργασία συμβάλλει σημαντικά στον τομέα της Αλγοριθμικής Δικαιοσύνης παρέχοντας ένα πρακτικό εργαλείο που ενισχύει τη διαφάνεια και προάγει τις ανησυχίες δικαιοσύνης καθ' όλη τη διάρκεια ανάπτυξης των μοντέλων ML. Η εφαρμογή αξιοποιεί το ισχυρό εργαλείο Aif360 από την IBM \cite{IBM2023} για την ανάλυση των δεδομένων που ανεβάζουν οι χρήστες και την ανίχνευση πιθανών προκαταλήψεων βάσει καθορισμένων από τον χρήστη χαρακτηριστικών, όπως η φυλή, το φύλο ή η ηλικία. Αυτό επιτρέπει στους χρήστες να εντοπίζουν περιοχές όπου τα μοντέλα τους μπορεί να παρουσιάζουν άδικες προτιμήσεις προς συγκεκριμένες δημογραφικές ομάδες.

Επιπλέον, η εφαρμογή προχωρά πέρα από την απλή ανίχνευση προκαταλήψεων, προτείνοντας κατάλληλες τεχνικές μείωσης προκαταλήψεων. Η εφαρμογή συνιστά κατάλληλους αλγόριθμους για τη μείωση του ανιχνευόμενου τύπου προκατάληψης, λαμβάνοντας υπόψη τα συγκεκριμένα χαρακτηριστικά των δεδομένων και τις πιθανές περιορισμούς. Αυτό δίνει τη δυνατότητα στους χρήστες να αντιμετωπίζουν ενεργά τις ανησυχίες δικαιοσύνης και να διασφαλίζουν ότι τα μοντέλα ML τους λειτουργούν με υπεύθυνο και ηθικό τρόπο.

Η εφαρμογή προωθεί τη συμμόρφωση με κανονισμούς όπως ο Τοπικός Νόμος 144 του 2021 που επιβάλλεται από το Τμήμα Προστασίας Καταναλωτών και Εργαζομένων της Νέας Υόρκης (DCWP) \cite{DCWP2021}. Αυτός ο νόμος απαιτεί διαφάνεια και δικαιοσύνη στα αυτοματοποιημένα συστήματα αποφάσεων, ευθυγραμμιζόμενος απόλυτα με τον στόχο μας για την προώθηση υπεύθυνων και ηθικών πρακτικών AI. Με την ενεργή μείωση των προκαταλήψεων και τη διασφάλιση της διαφάνειας στη διαδικασία ανάπτυξης μοντέλων, η εφαρμογή δίνει τη δυνατότητα στους χρήστες να συμμορφώνονται με τέτοιους κανονισμούς χωρίς να διακυβεύεται η λειτουργικότητα των \en ML\gr μοντέλων  τους.

\subsection{\gr Πρόβλημα}
\paragraph{}\gr Υπάρχουν πολλές αξιοσημείωτες περιπτώσεις που υπογραμμίζουν τη σημασία της δικαιοσύνης στα \en AI \gr συστήματα. Ένα χαρακτηριστικό παράδειγμα είναι το αυτοματοποιημένο εργαλείο πρόσληψης της \en Amazon \gr \cite{buddautomated}. Ξεκίνησε το \en 2014, \gr αυτό το εργαλείο χρησιμοποίησε ορισμένους αλγορίθμους για την αξιολόγηση βιογραφικών και την βαθμολόγηση υποψηφίων. Ωστόσο, μέχρι το \en 2015, \gr διαπιστώθηκε ότι το σύστημα πρόσληψης δεν βαθμολογούσε δίκαια τους υποψηφίους, καθώς ευνοούσε τους άντρες υποψηφίους έναντι των γυναικών. Αυτή η μεροληψία προέκυψε επειδή το εργαλείο είχε εκπαιδευτεί με βιογραφικά που είχαν υποβληθεί στην \en Amazon \gr κατά τη διάρκεια μιας δεκαετίας, τα περισσότερα από τα οποία προέρχονταν από άντρες  \cite{lewis2018will}.

\gr Ένα άλλο χαρακτηριστικό παράδειγμα είναι το λογισμικό \en COMPAS (Correctional Offender Management Profiling for Alternative Sanctions)\cite{goel2021accuracy} \gr που χρησιμοποιήθηκε από την κυβέρνηση των \en Η.Π.Α., \gr το οποίο υπολόγιζε βάσει των δεδομένων των κατηγορουμένων ένα σκορ (1 έως 10). Αυτά τα σκορ βοηθούσαν τους δικαστές να αποφασίσουν για ποινές, αναστολές και άλλες δικαστικές αποφάσεις. Ωστόσο, μελέτες αποκάλυψαν ότι ο αλγόριθμος είχε μεγαλύτερη πιθανότητα να προβλέψει λανθασμένα ότι οι μαύροι κατηγορούμενοι θα επαναλάμβαναν το έγκλημα σε σύγκριση με τους λευκούς κατηγορούμενους, οδηγώντας σε δυσανάλογες επιπτώσεις στις αποφάσεις για την ποινή και την αναστολή  \cite{lewandowski2021machine} .

\gr Αυτά τα παραδείγματα υπογραμμίζουν την κρίσιμη ανάγκη αντιμετώπισης των μεροληψιών στα \en AI \gr συστήματα για να διασφαλιστεί η δικαιοσύνη και η ισότητα. Η έρευνα συνεχίζει να εξερευνά μεθόδους για τον μετριασμό αυτών των μεροληψιών, όπως η ανάπτυξη πιο διαφανών αλγορίθμων και η ενσωμάτωση μετρήσεων δικαιοσύνης στον σχεδιασμό και την αξιολόγηση των \en AI \gr συστημάτων \cite{mehrabi2021survey}. Μία προσέγγιση είναι η χρήση τεχνικών μηχανικής μάθησης που είναι ευαίσθητες στη δικαιοσύνη και προσαρμόζουν τη διαδικασία μάθησης για να ελαχιστοποιήσουν τη μεροληψία. Μια άλλη μέθοδος είναι η διενέργεια ελέγχων μεροληψίας για τον εντοπισμό και τη διόρθωση των μεροληψιών πριν από την ανάπτυξη των \en AI \gr συστημάτων σε κρίσιμες εφαρμογές.

\gr Για παράδειγμα, η ενσωμάτωση περιορισμών δικαιοσύνης στη διαδικασία εκπαίδευσης μπορεί να βοηθήσει στη διασφάλιση ότι τα παραγόμενα μοντέλα δεν επηρεάζουν δυσανάλογα καμία συγκεκριμένη ομάδα \cite{dwork2012fairness}. Επιπλέον, η χρήση τεχνικών εξηγήσιμης \en AI \gr (\en XAI \gr) μπορεί να προσφέρει πληροφορίες για το πώς λαμβάνονται οι αποφάσεις από τα \en AI \gr συστήματα, καθιστώντας ευκολότερο τον εντοπισμό και τη διόρθωση της μεροληπτικής συμπεριφοράς.

\gr Οι πρόσφατες εξελίξεις στη μείωση της μεροληψίας περιλαμβάνουν την ανάπτυξη τεχνικών αντίπαλης αποπροκατάληψης (\en adversarial debiasing \gr), οι οποίες περιλαμβάνουν την εκπαίδευση των \en AI \gr μοντέλων με τρόπο που οι αντίπαλοι προσπαθούν να εισαγάγουν μεροληψία και το κύριο μοντέλο μαθαίνει να την εξουδετερώνει \cite{zhang2018mitigating}. Αυτή η μέθοδος έχει δείξει υποσχέσεις για τη μείωση της μεροληψίας σε διάφορες εφαρμογές, από τις προσλήψεις μέχρι τη δικαιοσύνη.

\gr Επιπλέον, υπάρχει αυξανόμενη έμφαση στη σημασία των διεπιστημονικών προσεγγίσεων, συνδυάζοντας γνώσεις από την πληροφορική, το δίκαιο, την ηθική και τις κοινωνικές επιστήμες για την αντιμετώπιση της μεροληψίας με ολοκληρωμένο τρόπο. Οι συνεργατικές προσπάθειες και οι περιεκτικές ερευνητικές πρακτικές είναι απαραίτητες για την ανάπτυξη ανθεκτικών λύσεων που εξασφαλίζουν ότι οι τεχνολογίες \en AI \gr ωφελούν δίκαια όλα τα τμήματα της κοινωνίας.

\gr Συνολικά, η αντιμετώπιση της μεροληψίας στα \en AI \gr είναι μια σύνθετη και διαρκής πρόκληση που απαιτεί συνεχή προσπάθεια και συνεργασία μεταξύ των επιστημών. Με τον συνδυασμό τεχνικών λύσεων με πολιτικές και κανονιστικά μέτρα, είναι δυνατόν να δημιουργηθούν \en AI \gr συστήματα που δεν είναι μόνο αποτελεσματικά αλλά και δίκαια και σωστά.


\subsection{\gr Δομή Διπλωματικής Εργασίας}
\paragraph{}\gr Στα πλαίσια της διπλωματικής εργασίας μελετήθηκαν διάφορες διεθνείς δημοσιεύσεις που αφορούν την έννοια της αλγοριθμικής δικαιοσύνης, τις μετρικές εκτίμησης της αλγοριθμικής μεροληψίας και τους αλγορίθμους μείωσης της. Η ιστοσελίδα κατασκευάστηκε με χρήση του \en Flask \gr \cite{grinberg2018flask}, ενώ οι λειτουργίες της που αφορούν τη μέτρηση και τη μείωση της αλγοριθμικής μεροληψίας υλοποιήθηκαν με τη βιβλιοθήκη \en AI Fairness 360 \gr της \en IBM \cite{bellamy2018ai}.

\paragraph{}\gr Στο κεφάλαιο 2 γίνεται βιβλιογραφική ανασκόπηση σχετικά με τη μηχανική μάθηση. Αρχικά, γίνεται αναλυτική παρουσίαση της έννοιας της αλγοριθμικής μεροληψίας και των σταδίων στα οποία μπορεί να εμφανιστεί. Στη συνέχεια, περιγράφεται η διαδικασία δημιουργίας ενός μοντέλου μηχανικής μάθησης με έμφαση στα \en binary \gr μοντέλα. Εξετάζονται τα κριτήρια αξιολόγησης των μοντέλων και παρουσιάζονται οι μετρικές και οι αλγόριθμοι μείωσης της μεροληψίας που συμπεριλήφθηκαν στην παρούσα εργασία. Επιπλέον, γίνεται μελέτη των νομικών και ηθικών ζητημάτων, όπως ο νόμος \en Local Law 144 of 2021 \gr.

\paragraph{}\gr Στο κεφάλαιο 3 παρουσιάζεται αναλυτικά η αρχιτεκτονική του συστήματος, ο σχεδιασμός και οι τεχνολογίες στις οποίες βασίζεται.

\paragraph{}\gr Στο κεφάλαιο 4 περιγράφεται η διαδικασία αξιολόγησης της εφαρμογής και τα αποτελέσματα που προέκυψαν από αυτή.

\paragraph{}\gr Στο κεφάλαιο 5 παρατίθενται τα συμπεράσματα από την αξιολόγηση και τα αποτελέσματα της εργασίας. Τέλος, σκιαγραφούνται οι μελλοντικές ερευνητικές κατευθύνσεις και τα ζητήματα που προκύπτουν από την εργασία, καθώς και οι περιορισμοί που εντοπίστηκαν κατά την υλοποίηση και την αξιολόγηση. Συγκεκριμένα, επισημαίνονται τα προβλήματα και οι προκλήσεις που συνδέονται με την εξασφάλιση της αλγοριθμικής δικαιοσύνης σε διαφορετικά πλαίσια εφαρμογής και προτείνονται λύσεις και κατευθύνσεις για περαιτέρω έρευνα. Οι περιορισμοί που εντοπίστηκαν περιλαμβάνουν την ανάγκη για μεγαλύτερα και πιο ποικίλα δεδομένα εκπαίδευσης, την αυξημένη πολυπλοκότητα των αλγορίθμων μείωσης της μεροληψίας, καθώς και την ανάγκη για συνεχή ενημέρωση και προσαρμογή στις τρέχουσες νομικές και ηθικές απαιτήσεις.

\subsection{\gr Συνεισφορά}
\paragraph{}\gr Η παρούσα διπλωματική εργασία εστιάζει στην ανάπτυξη ενός εργαλείου αξιολόγησης της αλγοριθμικής δικαιοσύνης, το οποίο ευθυγραμμίζεται πλήρως με τις προδιαγραφές του Νόμου 144 του 2021 (\en "Local Law 144 of 2021" \gr) της Νέας Υόρκης. Στόχος είναι να καταστήσουμε το εργαλείο εύχρηστο και προσβάσιμο σε χρήστες με ή χωρίς εξειδικευμένες γνώσεις, ώστε να μπορούν να αξιολογούν τη λειτουργία των μοντέλων τεχνητής νοημοσύνης που υλοποιούν, να εντοπίζουν τυχόν προκαταλήψεις και να υιοθετούν στρατηγικές για την μείωση ή την εξάλειψή τους.

\paragraph{}\gr Πέρα από την τήρηση του νομικού πλαισίου, το εργαλείο μας φιλοδοξεί να προσφέρει ουσιαστική αξία στον πραγματικό κόσμο, συμβάλλοντας στην υιοθέτηση ηθικών και δίκαιων εφαρμογών της τεχνητής νοημοσύνης σε διάφορους τομείς.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Βιβλιογραφική Επισκόπηση
\newpage
\thispagestyle{plain}
\null
\vspace{2cm}
\hspace{-6.5mm}{\textbf{\Huge
 \gr Κεφάλαιο 2}}
\vspace{-4mm}
\section{\gr Βιβλιογραφική Επισκόπηση}
\gr
\paragraph{}\gr
Η βιβλιογραφική επισκόπηση εστιάζει στην τρέχουσα κατάσταση της έρευνας στον τομέα της αλγοριθμικής προκατάληψης και της δικαιοσύνης στη μηχανική μάθηση. Η ενότητα αυτή καλύπτει διεξοδικά θεμελιώδεις έννοιες, μετρικές και τεχνικές μετριασμού που σχετίζονται με την παρούσα μελέτη. Επιπλέον, φέρνει στο προσκήνιο το νομικό πλαίσιο του Νόμου 144 του 2021 (\en Local Law 144 of 2021 ),\gr που θέτει το πλαίσιο για την τήρηση των κανονισμών στην παρούσα έρευνα.

\subsection{\gr Η μηχανική μάθηση}
\gr Η μηχανική μάθηση \en (ML) \gr είναι ένας υποτομέας της τεχνητης νοημοσύνης (\en AI) \gr που περιλαμβάνει την ανάπτυξη αλγορίθμων που επιτρέπουν στους υπολογιστές να μαθαίνουν από δεδομένα και να κάνουν προβλέψεις ή αποφάσεις με βάση αυτά. Σε αντίθεση με τον παραδοσιακό προγραμματισμό, όπου ο υπολογιστής ακολουθεί ρητές οδηγίες, τα μοντέλα μηχανική μάθηση εκπαιδεύονται σε δεδομένα για να αναγνωρίζουν πρότυπα και να λαμβάνουν αποφάσεις με ελάχιστη ανθρώπινη παρέμβαση.

\gr Υπάρχουν τρεις κύριοι τύποι \en μηχανικής μάθησης: \gr η επιβλεπόμενη μάθηση (\en supervised learning\gr), η μη επιβλεπόμενη μάθηση (\en unsupervised learning\gr) και η ενισχυτική μάθηση (\en reinforcement learning\gr). Στην επιβλεπόμενη μάθηση, το μοντέλο εκπαιδεύεται σε ένα δεδομένο σύνολο με ετικέτες, πράγμα που σημαίνει ότι κάθε παράδειγμα εκπαίδευσης συνοδεύεται από μια ετικέτα εξόδου. Παραδείγματα αλγορίθμων επιβλεπόμενης μάθησης περιλαμβάνουν την λογιστική παλινδρόμηση, τις \en support vector machines \gr και τα νευρωνικά δίκτυα. Η μη επιβλεπόμενη μάθηση περιλαμβάνει την εκπαίδευση ενός μοντέλου σε δεδομένα χωρίς ετικέτες, αναζητώντας κρυφά πρότυπα ή εσωτερικές δομές. Παραδείγματα περιλαμβάνουν αλγορίθμους ομαδοποίησης όπως το \en k-means \gr και η ιεραρχική ομαδοποίηση. Η ενισχυτική μάθηση είναι ένας τύπος μάθησης όπου ένας πράκτορας μαθαίνει να λαμβάνει αποφάσεις εκτελώντας ενέργειες σε ένα περιβάλλον για να μεγιστοποιήσει κάποια έννοια συνολικής ανταμοιβής.

\gr Η μηχανική μάθηση έχει εφαρμοστεί επιτυχώς σε διάφορους τομείς όπως η υγειονομική περίθαλψη, η χρηματοοικονομική, το μάρκετινγκ και τα αυτόνομα συστήματα, δείχνοντας τη δυνατότητά της να μετασχηματίσει βιομηχανίες αυτοματοποιώντας πολύπλοκες εργασίες και παρέχοντας πολύτιμες πληροφορίες από δεδομένα \citep{goodfellow2016deep, bishop2006pattern}.
\subsection{\gr Προεπεξεργασία δεδομένων εκμάθησης}

\subsection{\gr Μόντελα μηχανικής Μάθησης}

\subsection{\gr Μέθοδοι αξιολόγησης μοντέλου}

\subsection{\gr Μεροληψία στη μηχανική μάθηση}
\gr Η μεροληψία στη μηχανική μάθηση αναφέρεται σε συστηματικά λάθη που οδηγούν σε άδικα αποτελέσματα, ιδιαίτερα όταν αυτά τα αποτελέσματα μειονεκτούν συγκεκριμένες ομάδες ανθρώπων βάσει χαρακτηριστικών όπως η φυλή, το φύλο, η ηλικία ή η κοινωνικοοικονομική κατάσταση. Η μεροληψία μπορεί να εκδηλωθεί με διάφορες μορφές κατά τη διάρκεια της διαδικασίας \en machine learning, \gr από τη συλλογή και προεπεξεργασία δεδομένων έως την εκπαίδευση και την ανάπτυξη του μοντέλου.

\gr Υπάρχουν διάφοροι τύποι μεροληψίας που μπορούν να επηρεάσουν τα μοντέλα \en machine learning\gr:

\begin{itemize}
    \item \textbf{\gr Μεροληψία Επιλογής:} \gr Αυτό συμβαίνει όταν τα δεδομένα εκπαίδευσης δεν είναι αντιπροσωπευτικά του πληθυσμού στον οποίο θα εφαρμοστεί το μοντέλο. Για παράδειγμα, αν ένα σύστημα αναγνώρισης προσώπου εκπαιδευτεί κυρίως σε εικόνες ανοιχτόχρωμων ατόμων, μπορεί να έχει κακή απόδοση σε σκουρόχρωμα άτομα \citep{buolamwini2018gender}.
    \item \textbf{\gr Μεροληψία Μέτρησης:} \gr Αυτό συμβαίνει όταν τα δεδομένα που συλλέγονται για εκπαίδευση ή αξιολόγηση περιέχουν ανακρίβειες ή συστηματικά λάθη. Για παράδειγμα, αν τα σφάλματα καταχώρισης δεδομένων είναι πιο συνηθισμένα για συγκεκριμένες δημογραφικές ομάδες, το μοντέλο μπορεί να μάθει να συνδέει αυτά τα λάθη με τις ίδιες τις ομάδες.
    \item \textbf{\gr Αλγοριθμική Μεροληψία:} \gr Αυτός ο τύπος μεροληψίας συμβαίνει όταν το ίδιο το μοντέλο ή ο αλγόριθμος συμβάλλει σε μεροληπτικά αποτελέσματα. Για παράδειγμα, ορισμένοι αλγόριθμοι μπορεί να ευνοούν εγγενώς μια ομάδα έναντι άλλης αν δεν έχουν ρυθμιστεί σωστά ή αν ο σχεδιασμός τους δεν λαμβάνει υπόψη τις παραμέτρους δικαιοσύνης.
\end{itemize}

\gr Η κατανόηση και ο μετριασμός της μεροληψίας είναι κρίσιμης σημασίας, καθώς τα μεροληπτικά μοντέλα μπορούν να διαιωνίσουν και ακόμη και να ενισχύσουν τις υπάρχουσες ανισότητες, οδηγώντας σε επιζήμιες συνέπειες σε κρίσιμους τομείς όπως οι προσλήψεις, η χορήγηση δανείων, η ποινική δικαιοσύνη και η υγειονομική περίθαλψη \citep{barocas2016big, o2016weapons}.

\subsection{\gr Αλγοριθμική μεροληψία και δικαιοσύνη στη μηχανική μάθηση}
Η αλγοριθμική μεροληψία αποτελεί ένα σημαντικό ζήτημα στη μηχανική μάθηση, καθώς τα μοντέλα που εκπαιδεύονται σε δεδομένα μπορεί να αντικατοπτρίζουν και να ενισχύουν υπάρχουσες προκαταλήψεις στην κοινωνία. Αυτό μπορεί να οδηγήσει σε άδικες και άνισες αποφάσεις που επηρεάζουν αρνητικά μειονοτικές ομάδες.

Για παράδειγμα, ένα μοντέλο που εκπαιδεύεται σε δεδομένα για την πρόβλεψη της εγκληματικότητας μπορεί να είναι πιο πιθανό να ταξινομήσει άτομα από μειονοτικές ομάδες ως πιθανούς εγκληματίες, ακόμα κι αν δεν έχουν παραβεί τον νόμο.

Η δικαιοσύνη στη μηχανική μάθηση εστιάζει στην ανάπτυξη αλγορίθμων που είναι δίκαιοι, αμερόληπτοι και δεν διακρίνουν εις βάρος συγκεκριμένων ομάδων. Αυτό περιλαμβάνει την αναγνώριση και την αντιμετώπιση πιθανών πηγών μεροληψίας στα δεδομένα εκπαίδευσης, τον σχεδιασμό αλγορίθμων που είναι ανθεκτικοί στη μεροληψία και την ανάπτυξη τεχνικών για την αξιολόγηση της δικαιοσύνης των μοντέλων μηχανικής μάθησης.

Είναι σημαντικό να λαμβάνουμε υπόψη την αλγοριθμική μεροληψία και να υιοθετούμε πρακτικές για την προώθηση της δικαιοσύνης στη μηχανική μάθηση, καθώς τα μοντέλα μηχανικής μάθησης ολοένα και περισσότερο επηρεάζουν τις ζωές μας.

\subsubsection{\gr Δικαιοσύνη στην τεχνητή νοημοσύνη}
\gr Η δικαιοσύνη στην τεχνητή νοημοσύνη περιλαμβάνει την εξασφάλιση ότι τα μοντέλα μηχανικής μάθησης αντιμετωπίζουν όλους τους ανθρώπους και τις ομάδες με δίκαιο τρόπο, χωρίς διακρίσεις ή προτιμήσεις. Υπάρχουν διάφοροι ορισμοί και μετρικές για τη δικαιοσύνη, που αντικατοπτρίζουν διαφορετικές προοπτικές και στόχους:

\begin{itemize}
    \item \textbf{\gr Δημογραφική Ισοτιμία:} \gr Ένα μοντέλο ικανοποιεί τη δημογραφική ισοτιμία αν η πιθανότητα ενός θετικού αποτελέσματος είναι η ίδια για διαφορετικές δημογραφικές ομάδες. Για παράδειγμα, ένας αλγόριθμος πρόσληψης θα πρέπει να επιλέγει υποψηφίους από διαφορετικές φυλετικές ομάδες με παρόμοια ποσοστά, υποθέτοντας ίσα προσόντα \citep{hardt2016equality}.
    \item \textbf{\gr Ισότητα Ευκαιριών:} \gr Αυτό το κριτήριο δικαιοσύνης απαιτεί τα άτομα σε διαφορετικές ομάδες που είναι εξίσου καταρτισμένα να έχουν ίσες πιθανότητες να επιλεγούν. Για παράδειγμα, ένα μοντέλο πιστωτικής αξιολόγησης θα πρέπει να εγκρίνει δάνεια για καταρτισμένους αιτούντες με ίσα ποσοστά ανεξάρτητα από το φύλο τους.
    \item \textbf{\gr Ισοτιμία Αποτελεσμάτων:} \gr Ένα μοντέλο ικανοποιεί την ισοτιμία αποτελεσμάτων αν έχει ίσα ποσοστά αληθινών θετικών και ψευδών θετικών για διαφορετικές δημογραφικές ομάδες. Αυτό σημαίνει ότι η ακρίβεια του μοντέλου είναι συνεπής μεταξύ των ομάδων, μειώνοντας την πιθανότητα δυσανάλογα υψηλών ψευδών θετικών ή ψευδών αρνητικών για οποιαδήποτε συγκεκριμένη ομάδα.
\end{itemize}

\gr Η επίτευξη δικαιοσύνης στην τεχνητή νοημοσύνη είναι πρόκληση, καθώς διαφορετικές μετρικές δικαιοσύνης μπορεί να έρχονται σε σύγκρουση μεταξύ τους και η βελτιστοποίηση για μία μπορεί να οδηγήσει σε συμβιβασμούς σε μια άλλη. Επιπλέον, η δικαιοσύνη πρέπει να λαμβάνεται υπόψη στο πλαίσιο της συγκεκριμένης εφαρμογής και του κοινωνικού αντίκτυπου των αποφάσεων του μοντέλου \citep{chouldechova2020snapshot, kleinberg2018algorithmic}.

\subsubsection{\gr Σημασία της αλγοριθμικής και Δικαιοσύνης στη μηχανική μάθηση}
\gr Η σημασία της αντιμετώπισης της αλγοριθμικής μεροληψίας και της εξασφάλισης δικαιοσύνης στη μηχανική μάθηση δεν μπορεί να υπερεκτιμηθεί. Τα μεροληπτικά μοντέλα μπορούν να οδηγήσουν σε άδικη μεταχείριση ατόμων, διαιωνίζοντας και ενισχύοντας τις κοινωνικές ανισότητες. Αυτό είναι ιδιαίτερα ανησυχητικό σε εφαρμογές υψηλού κινδύνου όπως η ποινική δικαιοσύνη, η υγειονομική περίθαλψη, η χρηματοοικονομική και η απασχόληση.

\textbf{\gr Ποινική Δικαιοσύνη:} \gr Στο σύστημα ποινικής δικαιοσύνης, τα μεροληπτικά εργαλεία αξιολόγησης κινδύνου μπορούν να οδηγήσουν σε δυσανάλογα αυστηρές ποινές για τις μειονότητες. Μελέτες έχουν δείξει ότι ορισμένοι αλγόριθμοι που χρησιμοποιούνται για την πρόβλεψη των ποσοστών επανάληψης εγκλημάτων είναι μεροληπτικοί κατά των μαύρων κατηγορουμένων, οδηγώντας σε υψηλότερα ποσοστά ψευδών θετικών σε σύγκριση με τους λευκούς κατηγορούμενους \citep{angwin2016machine}.

\textbf{\gr Υγειονομική Περίθαλψη:} \gr Στην υγειονομική περίθαλψη, τα μεροληπτικά μοντέλα μπορούν να οδηγήσουν σε άνισα επίπεδα πρόσβασης στη θεραπεία και τη φροντίδα. Για παράδειγμα, ένα μοντέλο που εκπαιδεύτηκε κυρίως σε δεδομένα από άνδρες ασθενείς μπορεί να υποδιαγνώσει καταστάσεις που εμφανίζονται διαφορετικά σε γυναίκες ασθενείς, οδηγώντας σε υποβέλτιστη φροντίδα για τις γυναίκες \citep{obermeyer2019dissecting}.

\textbf{\gr Χρηματοοικονομική:} \gr Στον χρηματοοικονομικό τομέα, τα μεροληπτικά μοντέλα αξιολόγησης πιστοληπτικής ικανότητας μπορούν να αρνούνται δάνεια σε καταρτισμένους αιτούντες βάσει της φυλής ή της εθνικότητάς τους. Αυτή η διάκριση όχι μόνο επηρεάζει τις ευκαιρίες των ατόμων αλλά και διαιωνίζει τις οικονομικές ανισότητες \citep{bartlett2019consumer}.

\textbf{\gr Απασχόληση:} \gr Στις προσλήψεις, οι μεροληπτικοί αλγόριθμοι μπορούν να μειονεκτούν συγκεκριμένες δημογραφικές ομάδες, διαιωνίζοντας τις ανισότητες στο χώρο εργασίας. Για παράδειγμα, ένας αλγόριθμος πρόσληψης που εκπαιδεύτηκε σε βιογραφικά κυρίως από ένα φύλο ή μια φυλετική ομάδα μπορεί ακούσια να ευνοήσει υποψηφίους από αυτήν την ομάδα, υπονομεύοντας τις προσπάθειες για πολυμορφία και ένταξη \citep{raghavan2020mitigating}.

\gr Η αντιμετώπιση αυτών των ζητημάτων απαιτεί μια πολυδιάστατη προσέγγιση, συμπεριλαμβανομένης της ανάπτυξης και εφαρμογής μετρικών δικαιοσύνης, της χρήσης αλγορίθμων μετριασμού μεροληψίας και της καθιέρωσης νομικών και ηθικών κατευθυντήριων γραμμών. Εργαλεία όπως το \en IBM's AI Fairness 360 \gr παρέχουν πρακτικές λύσεις για την ανίχνευση και τον μετριασμό της μεροληψίας, προσφέροντας μια σειρά από μετρικές και αλγορίθμους που μπορούν να ενσωματωθούν στη διαδικασία μηχανική μάθηση για την προώθηση της δικαιοσύνης \citep{bellamy2019ai}.

\gr Επιπλέον, νομικά πλαίσια όπως το \en Local Law 144 of 2021, \gr που επιβάλλεται από το \en NYC Department of Consumer and Worker Protection (DCWP), \gr απαιτούν διαφάνεια και δικαιοσύνη στα αυτοματοποιημένα συστήματα απόφασης. Η συμμόρφωση με τέτοιους κανονισμούς εξασφαλίζει ότι οι οργανισμοί είναι υπεύθυνοι για τα αποτελέσματα των \en AI \gr συστημάτων τους και ότι τα άτομα προστατεύονται από τις διακριτικές πρακτικές.

\gr Συμπερασματικά, η επιδίωξη της δικαιοσύνης στην τεχνητή νοημοσύνη είναι ένα κρίσιμο συστατικό της υπεύθυνης ανάπτυξης τεχνητής νοημοσύνης. Με την κατανόηση και την αντιμετώπιση της αλγοριθμικής μεροληψίας, μπορούμε να κατασκευάσουμε πιο δίκαια και δίκαια συστήματα που ωφελούν όλα τα μέλη της κοινωνίας.


\subsection{\gr Μετρικές Δικαιοσύνης}

\subsection{\gr Αλγόριθμοι μείωσης μεροληψίας}

\subsection{\gr Τοπικός Νόμος 144 του 2021}

\gr Σύνοψη για χρήση σε εισαγωγή διπλωματικής εργασίας:
Ο σύγχρονος οργανωσιακός κόσμος υιοθετεί ολοένα και περισσότερο εργαλεία Τεχνητής Νοημοσύνης για βελτιστοποίηση των εσωτερικών διαδικασιών, συμπεριλαμβανομένων και των λειτουργιών Ανθρώπινου Δυναμικού. Η αξιοποίηση \en ΤΝ \gr για λήψη αποφάσεων πρόσληψης, απόλυσης ή προαγωγής φέρνει στο προσκήνιο εργασιακά ζητήματα και θέτει σε εφαρμογή νομοθεσίες περί ιδιωτικότητας, όπως ο Τοπικός Νόμος 144 της Νέας Υόρκης (\en NYC 144\gr), που επιβάλλει "Έλεγχο Αμεροληψίας" σε Αυτόματα Εργαλεία Λήψης Αποφάσεων Απασχόλησης (\en AEDT\gr) \cite{NYC144}. Το παρόν κεφάλαιο εστιάζει στον \en NYC 144 \gr και τις απαιτήσεις του.

\subsubsection{\gr Ανάλυση Τοπικού Νόμου 144 του 2021}
\gr Ο Τοπικός Νόμος 144 του 2021, που εφαρμόστηκε από το Τμήμα Προστασίας Καταναλωτών και Εργαζομένων της Νέας Υόρκης (\en DCWP\gr) και είναι σε ισχύ από τον Ιανουάριο του έτους 2023, είναι μια πρωτοποριακή ρύθμιση με στόχο τη μείωση της μεροληψίας στα Αυτοματοποιημένα Εργαλεία Λήψης Αποφάσεων για Προσλήψεις (\en AEDTs\gr). Ο νόμος απαιτεί από τους εργοδότες και τις υπηρεσίες απασχόλησης να διενεργούν ετήσιους ελέγχους μεροληψίας στα \en AEDTs \gr και να δημοσιοποιούν αυτούς τους ελέγχους, εξασφαλίζοντας διαφάνεια και λογοδοσία στις πρακτικές προσλήψεων \cite{DCI_Consulting}.

\subsubsection{\gr Διασταυρούμενη Μεροληψία}
Ο κανόνας των \en{four/fifths} (ή κανόνας των 80 τοις εκατό) \cite{prevue} είναι ένα σημαντικό εργαλείο για την αξιολόγηση της \en{αλγοριθμικής} δικαιοσύνης. Σύμφωνα με αυτόν τον κανόνα, μια συγκεκριμένη πρακτική θεωρείται ότι έχει \en{disparate impact} εάν το ποσοστό επιτυχίας μιας προστατευόμενης ομάδας είναι λιγότερο από το 80 τοις εκατό του ποσοστού επιτυχίας της ομάδας με την υψηλότερη επίδοση. Αυτή η μετρική χρησιμοποιείται για να αξιολογήσει αν υπάρχει ανισότητα στα αποτελέσματα μιας \en{αλγοριθμικής} απόφασης μεταξύ διαφορετικών ομάδων, όπως ορίζεται από τον \en{Title VII of the Civil Rights Act of 1964}. Η μετρική \en{disparate impact} επιτρέπει την αναγνώριση ανισοτήτων που δεν είναι άμεσα εμφανείς αλλά προκύπτουν από την εφαρμογή του \gr αλγόριθμου. Σχετική βιβλιογραφία περιλαμβάνει τα έργα των \cite{barocas2017} και την έκθεση της \cite{eeoc1978} για τον τρόπο υπολογισμού του \en{disparate impact}.

Ωστόσο, αυτή η προσέγγιση δεν ήταν αρκετή για να διασφαλίσει την πλήρη δικαιοσύνη και αμεροληψία των \en{αλγορίθμων}. Με την ψήφιση του \en{Τοπικού Νόμου 144 του 2021} στη Νέα Υόρκη, εισήχθη η έννοια της διασταυρούμενης (\en{intersectional}) μεροληψίας, η οποία εξετάζει τα διάφορα χαρακτηριστικά των \en{datasets} σε συνδυασμό και όχι μεμονωμένα. Αυτό σημαίνει ότι πρέπει να συνεχίζει να υπάρχει ο παραπάνω περιορισμός αλλά να εφαρμόζεται με βάση διασταυρούμενα χαρακτηριστικά (\en{intersectional attributes}). Ο νόμος αυτός επιδιώκει να εξαλείψει τη μεροληψία που μπορεί να προκύψει όταν ένας \en{αλγόριθμος} ευνοεί ή δυσχεραίνει ομάδες με βάση συνδυασμούς χαρακτηριστικών όπως το φύλο και η φυλή \cite{localLawNew, newLawSummary}.

Η προσέγγιση αυτή αναγνωρίζει ότι οι άνθρωποι δεν ανήκουν μόνο σε μία κατηγορία (π.χ. φύλο ή φυλή), αλλά σε πολλές ταυτόχρονα, και ότι η δίκαιη αντιμετώπιση πρέπει να λαμβάνει υπόψη αυτές τις πολυπλοκότητες. Σχετική βιβλιογραφία για την διασταυρούμενη μεροληψία περιλαμβάνει τα έργα της \cite{crenshaw1989} και τη μελέτη των \cite{rieke2018} για τη μεροληψία στους αλγόριθμους αναγνώρισης προσώπου.


\subsubsection{\gr Αντιμετώπιση της Διασταυρούμενης Μεροληψίας}
\gr Ο Τοπικός Νόμος 144 εστιάζει στις διασταυρούμενες ομάδες, κάτι που είναι ιδιαίτερα κρίσιμο για την κατανόηση του πώς οι μεροληψίες μπορούν να επηρεάσουν δυσανάλογα τα άτομα που ανήκουν σε πολλαπλές περιθωριοποιημένες ομάδες. Τα παραδοσιακά μέτρα κατά των διακρίσεων συχνά αποτυγχάνουν να καταγράψουν τις σύνθετες μεροληψίες που αντιμετωπίζει, για παράδειγμα, μια μαύρη γυναίκα σε σύγκριση με έναν λευκό άνδρα. Οι διατάξεις του νόμου διασφαλίζουν ότι οι έλεγχοι μεροληψίας πρέπει να λαμβάνουν υπόψη διάφορες δημογραφικές ομάδες, συμπεριλαμβανομένων των διασταυρούμενων ταυτοτήτων, προωθώντας πιο δίκαιες πρακτικές προσλήψεων \cite{IntersectionalBias}.

\subsubsection{\gr Αξιοποίηση του Εργαλείου AIF360}
\gr Το εργαλείο AI Fairness 360 (AIF360) είναι μια ολοκληρωμένη σουίτα μέτρων σχεδιασμένη για την ανίχνευση και μείωση της μεροληψίας στα μοντέλα μηχανικής μάθησης. Περιλαμβάνει εργαλεία για την αξιολόγηση της μεροληψίας σε διάφορες δημογραφικές ομάδες, παρέχοντας λεπτομερή ανάλυση που ευθυγραμμίζεται με τις απαιτήσεις του Τοπικού Νόμου 144. Εφαρμόζοντας το AIF360, οι οργανισμοί μπορούν να αξιολογούν τα AEDT τους για μεροληψίες τόσο ενάντια σε προνομιούχες ομάδες (π.χ., λευκοί άνδρες) όσο και σε μη προνομιούχες ομάδες (π.χ., μαύρες γυναίκες) αποτελεσματικά \cite{AIF360}.

\subsubsection{\gr Πρακτική Εφαρμογή και Προκλήσεις}
\gr Παρόλο που το εργαλείο \en AIF360 \gr προσφέρει ισχυρές μετρικές για τον εντοπισμό μεροληψιών, υπάρχουν αρκετές πρακτικές προκλήσεις στην αποτελεσματική εφαρμογή αυτών των εργαλείων:

Απαιτήσεις Δεδομένων: Το \en AIF360 \gr απαιτεί λεπτομερή δημογραφικά δεδομένα, τα οποία μπορεί να είναι δύσκολο να αποκτηθούν και να επαληθευτούν. Ο Τοπικός Νόμος 144 αντιμετωπίζει αυτό το ζήτημα απαιτώντας οι έλεγχοι μεροληψίας να αναφέρουν τον αριθμό των ατόμων που δεν παρείχαν δημογραφικά δεδομένα, εξασφαλίζοντας διαφάνεια στα δεδομένα που χρησιμοποιούνται για αυτούς τους ελέγχους \cite{BiasMitigation2023}.

Σύνθετα Μοντέλα: Η αποτελεσματικότητα του εργαλείου μπορεί να διαφέρει ανάλογα με την πολυπλοκότητα των \en AEDTs\gr. Είναι κρίσιμο να εξερευνηθούν σενάρια όπου το \en AIF360 \gr μπορεί να μην αποδίδει καλά, ιδιαίτερα σε μοντέλα με σύνθετες διαδικασίες λήψης αποφάσεων \cite{AIModelComplexity}.

Ανθρώπινη Μεροληψία στο Σχεδιασμό: Ακόμη και με προηγμένα εργαλεία όπως το \en AIF360\gr, οι ανθρώπινες μεροληψίες κατά τον σχεδιασμό και την εφαρμογή των \en AEDTs \gr μπορεί να παραμένουν. Ο Τοπικός Νόμος 144 αντιμετωπίζει έμμεσα αυτό το ζήτημα υπογραμμίζοντας την ανάγκη για εξωτερικούς ελέγχους, οι οποίοι μπορούν να παρέχουν αντικειμενική αξιολόγηση αυτών των εργαλείων \cite{EthicalAI}.

\subsubsection{\gr Ενίσχυση της Διαφάνειας με την Επεξηγήσιμη Τεχνητή Νοημοσύνη (\en XAI\gr)}
\gr Η Καθηγήτρια Sarah Jones από το \en MIT \gr υπογραμμίζει τη δυναμική της Επεξηγήσιμης Τεχνητής Νοημοσύνης (\en XAI\gr) να συμπληρώνει τα εργαλεία εντοπισμού μεροληψίας. Οι τεχνικές \en XAI \gr μπορούν να παρέχουν πληροφορίες για το πώς τα \en AEDTs \gr καταλήγουν στις αποφάσεις τους, καθιστώντας τη διαδικασία προσλήψεων πιο διαφανή τόσο για τους εργοδότες όσο και για τους υποψήφιους. Αυτή η διαφάνεια είναι ουσιώδης για την οικοδόμηση εμπιστοσύνης και την εξασφάλιση συμμόρφωσης με τον Τοπικό Νόμο 144 \cite{Jones2023}.

\subsubsection{\gr Επιπτώσεις}
\gr Ο Τοπικός Νόμος 144 μπορεί να λειτουργήσει ως πρότυπο για παρόμοιες ρυθμίσεις. Η έμφαση του στη διαφάνεια, τη διασταυρούμενη ανάλυση και τους τακτικούς ελέγχους θέτει υψηλά πρότυπα για δίκαιες πρακτικές προσλήψεων. Ωστόσο, η άμεση εφαρμογή αυτού του νόμου σε διαφορετικά πολιτιστικά πλαίσια μπορεί να αντιμετωπίσει προκλήσεις, όπως οι διαφορετικές ορισμοί της μεροληψίας και τα διαφορετικά ρυθμιστικά τοπία. Η εξερεύνηση αυτών των ευρύτερων επιπτώσεων μπορεί να παρέχει μια πιο ολοκληρωμένη κατανόηση του παγκόσμιου αντίκτυπού του \cite{GlobalAIRegulations}. Η έμφαση του νόμου στους τακτικούς ελέγχους μεροληψίας και την λεπτομερή αναφορά δημογραφικών δεδομένων διασφαλίζει ότι οι αποχρώσεις των διασταυρούμενων μεροληψιών αντιμετωπίζονται, θέτοντας ένα προηγούμενο για μελλοντικές ρυθμίσεις στην Τεχνητή Νοημοσύνη και τις πρακτικές προσλήψεων \cite{AITransparency}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\gr
\en
\thispagestyle{plain}
\renewcommand{\bibname}{\gr Βιβλιογραφία}
\bibliographystyle{unsrt}%unsrt}
\bibliography{references}
\end{document}
