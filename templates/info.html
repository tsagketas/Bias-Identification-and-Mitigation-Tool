<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>University of Patras - Bias Detection Tool Thesis</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>University of Patras - Bias Detection in Machine Learning Methods</h1>
    </header>

    <section>
        <h2>Overview of the Thesis</h2>
        <p>
            This thesis, submitted to the University of Patras, focuses on the development of a web-based tool aimed at detecting and mitigating bias in machine learning algorithms. The project is particularly relevant in light of recent concerns surrounding the fairness and transparency of automated decision-making systems. The tool has been developed to help identify potential biases in machine learning models and reduce them through specific algorithms.
        </p>
    </section>

    <section>
        <h2>Purpose and Goals</h2>
        <p>
            The primary goal of this tool is to provide users, especially those without advanced programming knowledge, with an accessible platform for analyzing machine learning models for bias. By uploading datasets, users can evaluate their models using fairness metrics and employ bias mitigation techniques to ensure that their models operate ethically and transparently. The tool guides users in selecting the appropriate fairness metrics and mitigation algorithms based on the characteristics of their data.
        </p>
    </section>

    <section>
        <h2>Technical Details</h2>
        <p>
            Developed using Python and the Flask framework, the tool leverages IBM's AIF360 library, a well-established resource for fairness in AI. It allows users to check for bias in key demographic attributes such as race, gender, or age. The system also recommends algorithms for bias reduction based on the type of bias identified. It is designed to ensure that the results comply with legal frameworks, including the NYC Bias Audit Law of 2021, which requires fairness and transparency in automated decision-making systems.
        </p>
    </section>

    <section>
        <h2>Compliance with the NYC Bias Audit Law</h2>
        <p>
            In line with the NYC Bias Audit Law of 2021, the developed tool ensures that machine learning models meet regulatory requirements for fairness. This law, enforced by the NYC Department of Consumer and Worker Protection (DCWP), mandates that automated decision-making systems must avoid bias against specific population groups. The tool provides a practical solution for companies or developers aiming to comply with such legal requirements while maintaining model efficiency.
        </p>
    </section>

    <section>
        <h2>Impact and Future Extensions</h2>
        <p>
            The tool is intended to foster greater awareness and understanding of algorithmic fairness, promoting responsible AI practices. It aims to be a helpful resource not only for technical experts but also for non-technical users, policymakers, and organizations concerned with ethical AI development. Future improvements to the tool may include support for additional fairness metrics, more sophisticated bias reduction algorithms, and expanded compatibility with various machine learning models.
        </p>
    </section>

    <footer>
        <p>&copy; 2024 University of Patras - Developed as part of the Master's Thesis of Orestis I. Tsangetas</p>
    </footer>
</body>
</html>
